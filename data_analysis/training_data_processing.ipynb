{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb Cell 1\u001b[0m line \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W0sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m thresholded_frame \u001b[39m=\u001b[39m threshold_frame(frame_difference)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W0sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# Find contours in the thresholded frame\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W0sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m contours, _ \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mfindContours(thresholded_frame, cv2\u001b[39m.\u001b[39;49mRETR_EXTERNAL, cv2\u001b[39m.\u001b[39;49mCHAIN_APPROX_SIMPLE)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W0sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Draw rectangles around moving objects\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W0sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mfor\u001b[39;00m contour \u001b[39min\u001b[39;00m contours:\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/contours.cpp:197: error: (-210:Unsupported format or combination of formats) [Start]FindContours supports only CV_8UC1 images when mode != CV_RETR_FLOODFILL otherwise supports CV_32SC1 images only in function 'cvStartFindContours_Impl'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to calculate absolute difference between two frames\n",
    "def frame_diff(prev_frame, current_frame, next_frame):\n",
    "    diff1 = cv2.absdiff(next_frame, current_frame)\n",
    "    diff2 = cv2.absdiff(current_frame, prev_frame)\n",
    "    return cv2.bitwise_and(diff1, diff2)\n",
    "\n",
    "# Function to threshold the frame\n",
    "def threshold_frame(frame_diff):\n",
    "    _, thresh = cv2.threshold(frame_diff, 30, 255, cv2.THRESH_BINARY)\n",
    "    return thresh\n",
    "\n",
    "# Read video file or capture from camera (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('/Users/edwardamoah/Downloads/2023-05-10_17_46_37.mp4')\n",
    "\n",
    "# Read three frames to initialize\n",
    "prev_frame = cap.read()[1]\n",
    "current_frame = cap.read()[1]\n",
    "next_frame = cap.read()[1]\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Convert frames to grayscale\n",
    "    gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Calculate frame difference\n",
    "    frame_difference = frame_diff(prev_frame, current_frame, next_frame)\n",
    "\n",
    "    # Threshold the frame\n",
    "    thresholded_frame = threshold_frame(frame_difference)\n",
    "\n",
    "    # Find contours in the thresholded frame\n",
    "    contours, _ = cv2.findContours(thresholded_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw rectangles around moving objects\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:  # You can adjust this threshold based on your specific case\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(current_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Motion Detection', current_frame)\n",
    "\n",
    "    # Update frames for the next iteration\n",
    "    prev_frame = current_frame\n",
    "    current_frame = next_frame\n",
    "    _, next_frame = cap.read()\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Read video file or capture from camera (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('/Users/edwardamoah/Downloads/2023-05-10_17_46_37.mp4')\n",
    "\n",
    "# Read the first frame\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "# Convert the frame to grayscale\n",
    "prev_frame_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read the next frame\n",
    "    ret, current_frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    current_frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the absolute difference between the current frame and the previous frame\n",
    "    frame_diff = cv2.absdiff(current_frame_gray, prev_frame_gray)\n",
    "    \n",
    "    # Apply thresholding to the difference frame\n",
    "    _, thresholded_frame = cv2.threshold(frame_diff, 10, 255, cv2.THRESH_BINARY)\n",
    "    # Adjust the threshold value (10) to make the motion detection more sensitive\n",
    "    \n",
    "    # Find contours in the thresholded frame\n",
    "    contours, _ = cv2.findContours(thresholded_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw rectangles around moving objects\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 500:  # You can adjust this threshold based on your specific case\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(current_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Motion Detection', current_frame)\n",
    "    \n",
    "    # Update the previous frame\n",
    "    prev_frame_gray = current_frame_gray\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object and close all windows\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb Cell 3\u001b[0m line \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W2sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m area \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcontourArea(contour)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W2sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m perimeter \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39marcLength(contour, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m circularity \u001b[39m=\u001b[39m \u001b[39m4\u001b[39;49m \u001b[39m*\u001b[39;49m np\u001b[39m.\u001b[39;49mpi \u001b[39m*\u001b[39;49m area \u001b[39m/\u001b[39;49m (perimeter \u001b[39m*\u001b[39;49m perimeter)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# Adjust the circularity threshold based on your specific case\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mif\u001b[39;00m circularity \u001b[39m<\u001b[39m \u001b[39m0.7\u001b[39m:\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read video file or capture from camera (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('/Users/edwardamoah/Downloads/2023-05-10_17_46_37.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read the next frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Apply adaptive thresholding to segment the dark regions\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Iterate over the contours and detect circular dark holes\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        perimeter = cv2.arcLength(contour, True)\n",
    "        circularity = 4 * np.pi * area / (perimeter * perimeter)\n",
    "        \n",
    "        # Adjust the circularity threshold based on your specific case\n",
    "        if circularity < 0.7:\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Dark Hole Detection', frame)\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb Cell 4\u001b[0m line \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m cap \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mVideoCapture(\u001b[39m'\u001b[39m\u001b[39m/Users/edwardamoah/Documents/GitHub/BeeVision/data/2023-05-10_17_46_37.mp4\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39mwhile\u001b[39;00m cap\u001b[39m.\u001b[39misOpened():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     ret, frame \u001b[39m=\u001b[39m cap\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ret:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Function to detect circular holes in a frame\n",
    "def detect_circles(frame):\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply GaussianBlur to reduce noise and improve circle detection\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Use Hough Circle Transform to detect circles\n",
    "    circles = cv2.HoughCircles(\n",
    "        blurred, cv2.HOUGH_GRADIENT, dp=1, minDist=50,\n",
    "        param1=100, param2=30, minRadius=10, maxRadius=50\n",
    "    )\n",
    "\n",
    "    if circles is not None:\n",
    "        # Convert circle coordinates to integer\n",
    "        circles = np.uint16(np.around(circles))\n",
    "\n",
    "        # Draw circles on the original frame\n",
    "        for i in circles[0, :]:\n",
    "            cv2.circle(frame, (i[0], i[1]), i[2], (0, 255, 0), 2)  # Draw outer circle\n",
    "            cv2.circle(frame, (i[0], i[1]), 2, (0, 0, 255), 3)  # Draw center of the circle\n",
    "\n",
    "# Read video file or capture from camera (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('/Users/edwardamoah/Documents/GitHub/BeeVision/data/2023-05-10_17_46_37.mp4')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect circles in the current frame\n",
    "    detect_circles(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Circle Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb Cell 5\u001b[0m line \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W4sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     prev_frame_gray \u001b[39m=\u001b[39m current_frame_gray\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W4sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     \u001b[39m# Break the loop if 'q' key is pressed\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W4sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39;49mwaitKey(\u001b[39m1\u001b[39;49m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W4sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/edwardamoah/Documents/GitHub/BeeVision/data_analysis/training_data_processing.ipynb#W4sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Release the capture object and close all windows\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Read video file or capture from camera (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('/Users/edwardamoah/Documents/GitHub/BeeVision/data/videos/2023-05-10_17_46_37.mp4')\n",
    "\n",
    "#filename = '/Users/edwardamoah/Documents/GitHub/BeeVision/data/videos/2023-05-10_17_46_37.mp4'\n",
    "\n",
    "# Read the first frame\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "# Convert the frame to grayscale\n",
    "prev_frame_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Counter for saved frames\n",
    "frame_counter = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read the next frame\n",
    "    ret, current_frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    current_frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the absolute difference between the current frame and the previous frame\n",
    "    frame_diff = cv2.absdiff(current_frame_gray, prev_frame_gray)\n",
    "    \n",
    "    # Apply thresholding to the difference frame\n",
    "    _, thresholded_frame = cv2.threshold(frame_diff, 10, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours in the thresholded frame\n",
    "    contours, _ = cv2.findContours(thresholded_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw rectangles around moving objects and save frames with motion\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 200:  # You can adjust this threshold based on your specific case\n",
    "            (x, y, w, h) = cv2.boundingRect(contour)\n",
    "            \n",
    "            cv2.rectangle(current_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Save the frame with motion as an image\n",
    "            frame_name = f\"/Users/edwardamoah/Documents/GitHub/BeeVision/data/images/motion_frame_{frame_counter}.jpg\"\n",
    "            cv2.imwrite(frame_name, current_frame)\n",
    "            frame_counter += 1\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Motion Detection', current_frame)\n",
    "    \n",
    "    # Update the previous frame\n",
    "    prev_frame_gray = current_frame_gray\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Read video file or capture from camera (replace 'your_video.mp4' with your video file)\n",
    "cap = cv2.VideoCapture('/Users/edwardamoah/Documents/GitHub/BeeVision/data/videos/2023-05-10_17_46_37.mp4')\n",
    "\n",
    "#filename = '/Users/edwardamoah/Documents/GitHub/BeeVision/data/videos/2023-05-10_17_46_37.mp4'\n",
    "\n",
    "# Read the first frame\n",
    "ret, prev_frame = cap.read()\n",
    "\n",
    "# Convert the frame to grayscale\n",
    "prev_frame_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Counter for saved frames\n",
    "frame_counter = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read the next frame\n",
    "    ret, current_frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    current_frame_gray = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calculate the absolute difference between the current frame and the previous frame\n",
    "    frame_diff = cv2.absdiff(current_frame_gray, prev_frame_gray)\n",
    "    \n",
    "    # Apply thresholding to the difference frame\n",
    "    _, thresholded_frame = cv2.threshold(frame_diff, 10, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Find contours in the thresholded frame\n",
    "    contours, _ = cv2.findContours(thresholded_frame, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Save frames with motion\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) > 200:  # You can adjust this threshold based on your specific case\n",
    "            # Save the frame with motion as an image\n",
    "            frame_name = f\"/Users/edwardamoah/Documents/GitHub/BeeVision/data/images/motion_frame_{frame_counter}.jpg\"\n",
    "            cv2.imwrite(frame_name, current_frame)\n",
    "            frame_counter += 1\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Motion Detection', current_frame)\n",
    "    \n",
    "    # Update the previous frame\n",
    "    prev_frame_gray = current_frame_gray\n",
    "    \n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the capture object and close all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.12-py3-none-any.whl (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyparsing==2.4.7\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from roboflow) (1.23.3)\n",
      "Collecting idna==2.10\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from roboflow) (1.16.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from roboflow) (6.0)\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting requests-toolbelt\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi==2023.7.22\n",
      "  Using cached certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "Collecting supervision\n",
      "  Downloading supervision-0.17.1-py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.5/77.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from roboflow) (9.2.0)\n",
      "Requirement already satisfied: matplotlib in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from roboflow) (3.6.0)\n",
      "Requirement already satisfied: requests in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from roboflow) (2.28.1)\n",
      "Collecting python-magic\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Collecting chardet==4.0.0\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from roboflow) (4.64.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from roboflow) (1.4.4)\n",
      "Collecting opencv-python-headless==4.8.0.74\n",
      "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-macosx_11_0_arm64.whl (33.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from roboflow) (2.8.2)\n",
      "Collecting cycler==0.10.0\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from roboflow) (1.26.11)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from matplotlib->roboflow) (4.37.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from matplotlib->roboflow) (1.0.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from matplotlib->roboflow) (21.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from requests->roboflow) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.9.0 in /Users/edwardamoah/opt/anaconda3/envs/geoanalysis_env/lib/python3.10/site-packages (from supervision->roboflow) (1.9.1)\n",
      "Collecting Pillow>=7.1.2\n",
      "  Downloading Pillow-10.1.0-cp310-cp310-macosx_11_0_arm64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: python-magic, python-dotenv, pyparsing, Pillow, opencv-python-headless, idna, cycler, chardet, certifi, requests-toolbelt, supervision, roboflow\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: Pillow\n",
      "    Found existing installation: Pillow 9.2.0\n",
      "    Uninstalling Pillow-9.2.0:\n",
      "      Successfully uninstalled Pillow-9.2.0\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.7.0.72\n",
      "    Uninstalling opencv-python-headless-4.7.0.72:\n",
      "      Successfully uninstalled opencv-python-headless-4.7.0.72\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.11.0\n",
      "    Uninstalling cycler-0.11.0:\n",
      "      Successfully uninstalled cycler-0.11.0\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2022.12.7\n",
      "    Uninstalling certifi-2022.12.7:\n",
      "      Successfully uninstalled certifi-2022.12.7\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "image-slicer 2.1.1 requires Pillow==7.2.0, but you have pillow 10.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Pillow-10.1.0 certifi-2023.7.22 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 python-magic-0.4.27 requests-toolbelt-1.0.0 roboflow-1.1.12 supervision-0.17.1\n"
     ]
    }
   ],
   "source": [
    "!pip install roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.196`, to intall it `pip install ultralytics==8.0.196`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Solitary-Bees-1 to yolov8:: 100%|██████████| 1011/1011 [00:00<00:00, 4896.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Solitary-Bees-1 in yolov8:: 100%|██████████| 52/52 [00:00<00:00, 7792.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"lMVaMrM489NnOBcHhZJ4\")\n",
    "project = rf.workspace(\"beevision\").project(\"solitary-bees\")\n",
    "dataset = project.version(1).download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geoanalysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
